{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21dcae54-a1a7-45b3-847c-93630caa0270",
   "metadata": {},
   "source": [
    "# Full chain inference\n",
    "\n",
    "In this notebook, we will:\n",
    " * Take a look at what a complete ML reconstruction configuration look like\n",
    " * Understand what are the high-level represntations built out of the raw ML output\n",
    " * Understand how to visualize the data representations\n",
    " * Learn how to store the output of the ML reconstruction to file\n",
    " * Learn how to load an HDF5 file to back to a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c85427",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # Should return True if CUDA is accessible\n",
    "print(torch.cuda.device_count())  # Should return the number of available GPUs\n",
    "print(torch.cuda.get_device_name(0))  # Should return the name of the GPU (e.g., 'NVIDIA A100')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d21c115-f4aa-4202-8a75-36c405003392",
   "metadata": {
    "tags": []
   },
   "source": [
    "***\n",
    "***\n",
    "## 1. Full Chain Inference Configuration\n",
    "\n",
    "We start by pointing the python path to the reco chain package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "974fdc34-f7a3-430e-b269-f70e1f70561d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# SOFTWARE_DIR = '/sdf/data/neutrino/software/spine/' # Change this path to your software install\n",
    "SOFTWARE_DIR = '/home/azam/spine_bilal/spine'  # Your software install location\n",
    "\n",
    "\n",
    "# Set software directory\n",
    "sys.path.insert(0, SOFTWARE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dca1e1b-00f8-48a8-88ab-e0f477fb10a6",
   "metadata": {},
   "source": [
    "Now let's take a look at a full chain configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b205e89d-14fa-48e0-b2ac-29b82e0479fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['snapshot--999.ckpt']\n"
     ]
    }
   ],
   "source": [
    "#ls /mnt/eagle/clone/g2/projects/Nu_Novel/Tutorials/spine_workshop_2024/data_samples/weights\n",
    "#ls /home/azam/spine_bilal/weights/uresnet\n",
    "import os\n",
    "\n",
    "# List the contents of the weights directory\n",
    "weights_path = '/home/azam/spine_bilal/weights/grappa_shower'\n",
    "weights_files = os.listdir(weights_path)\n",
    "print(weights_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ff55409-68c1-49af-8403-391bc5cade55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['snapshot-999.ckpt']\n"
     ]
    }
   ],
   "source": [
    "#ls /mnt/eagle/clone/g2/projects/Nu_Novel/Tutorials/spine_workshop_2024/data_samples/weights\n",
    "#ls /home/azam/spine_bilal/weights/uresnet\n",
    "import os\n",
    "\n",
    "# List the contents of the weights directory\n",
    "weights_path = '/home/azam/spine_bilal/weights/uresnet'\n",
    "weights_files = os.listdir(weights_path)\n",
    "print(weights_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46d4e14a-9db4-46e1-8d7d-df9ad30bf3f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFile**\t\t/mnt/eagle/clone/g2/projects/Nu_Novel/DUNE/DUNE_2x2_RHC_MLreco_MR6/train_10_11.root\t\n",
      " TFile*\t\t/mnt/eagle/clone/g2/projects/Nu_Novel/DUNE/DUNE_2x2_RHC_MLreco_MR6/train_10_11.root\t\n",
      "  KEY: TTree\tparticle_pcluster_tree;1\tpcluster tree\n",
      "  KEY: TTree\tsparse3d_pcluster_tree;1\tpcluster tree\n",
      "  KEY: TTree\tsparse3d_hits_tree;1\thits tree\n",
      "  KEY: TTree\tsparse3d_pcluster_semantics_tree;1\tpcluster_semantics tree\n",
      "  KEY: TTree\tcluster3d_pcluster_tree;1\tpcluster tree\n",
      "  KEY: TTree\tcluster3d_pcluster_dedx_tree;1\tpcluster_dedx tree\n",
      "  KEY: TTree\tneutrino_mc_truth_tree;1\tmc_truth tree\n",
      "  KEY: TTree\ttrigger_base_tree;1\tbase tree\n"
     ]
    }
   ],
   "source": [
    "import ROOT\n",
    "\n",
    "# Open the ROOT file\n",
    "#file = ROOT.TFile.Open(\"/mnt/eagle/clone/g2/projects/Nu_Novel/Tutorials/spine_workshop_2024/data_samples/Small_LArCV_files/generic_small.root\")\n",
    "file = ROOT.TFile.Open(\"/mnt/eagle/clone/g2/projects/Nu_Novel/DUNE/DUNE_2x2_RHC_MLreco_MR6/train_10_11.root\")\n",
    "# List all the objects inside the ROOT file (including trees)\n",
    "file.ls()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac12aade-23ca-43d0-9b41-9a1869bd9ecc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base:\n",
      "  world_size: 1\n",
      "  iterations: -1\n",
      "  seed: 0\n",
      "  dtype: float32\n",
      "  unwrap: true\n",
      "  log_dir: /home/azam/spine_bilal/logs/inference_logs\n",
      "  prefix_log: true\n",
      "  overwrite_log: false\n",
      "  log_step: 1\n",
      "io:\n",
      "  loader:\n",
      "    batch_size: 6\n",
      "    shuffle: false\n",
      "    num_workers: 4\n",
      "    collate_fn: all\n",
      "    dataset:\n",
      "      name: larcv\n",
      "      file_keys: /mnt/eagle/clone/g2/projects/Nu_Novel/DUNE/DUNE_2x2_RHC_MLreco_MR6/train_10_11.root\n",
      "      schema:\n",
      "        data:\n",
      "          parser: sparse3d\n",
      "          sparse_event: sparse3d_pcluster\n",
      "        seg_label:\n",
      "          parser: sparse3d\n",
      "          sparse_event: sparse3d_pcluster_semantics\n",
      "        ppn_label:\n",
      "          parser: particle_points\n",
      "          sparse_event: sparse3d_pcluster\n",
      "          particle_event: particle_pcluster\n",
      "        clust_label:\n",
      "          parser: cluster3d\n",
      "          cluster_event: cluster3d_pcluster\n",
      "          particle_event: particle_pcluster\n",
      "          sparse_semantics_event: sparse3d_pcluster_semantics\n",
      "          add_particle_info: true\n",
      "          clean_data: true\n",
      "        coord_label:\n",
      "          parser: particle_coords\n",
      "          particle_event: particle_pcluster\n",
      "          cluster_event: cluster3d_pcluster\n",
      "        graph_label:\n",
      "          parser: particle_graph\n",
      "          particle_event: particle_pcluster\n",
      "        particles:\n",
      "          parser: particle\n",
      "          particle_event: particle_pcluster\n",
      "          cluster_event: cluster3d_pcluster\n",
      "        meta:\n",
      "          parser: meta3d\n",
      "          sparse_event: sparse3d_pcluster\n",
      "        run_info:\n",
      "          parser: run_info\n",
      "          sparse_event: sparse3d_pcluster\n",
      "model:\n",
      "  name: full_chain\n",
      "  weight_path: /home/azam/spine_bilal/weights/\n",
      "  to_numpy: true\n",
      "  network_input:\n",
      "    data: data\n",
      "    seg_label: seg_label\n",
      "    clust_label: clust_label\n",
      "  loss_input:\n",
      "    seg_label: seg_label\n",
      "    ppn_label: ppn_label\n",
      "    clust_label: clust_label\n",
      "    coord_label: coord_label\n",
      "  modules:\n",
      "    chain:\n",
      "      deghosting: null\n",
      "      charge_rescaling: null\n",
      "      segmentation: uresnet\n",
      "      point_proposal: ppn\n",
      "      fragmentation: graph_spice\n",
      "      shower_aggregation: grappa\n",
      "      shower_primary: grappa\n",
      "      track_aggregation: grappa\n",
      "      particle_aggregation: null\n",
      "      inter_aggregation: grappa\n",
      "      particle_identification: grappa\n",
      "      primary_identification: grappa\n",
      "      orientation_identification: grappa\n",
      "      calibration: null\n",
      "    uresnet_ppn:\n",
      "      uresnet:\n",
      "        num_input: 1\n",
      "        num_classes: 5\n",
      "        filters: 32\n",
      "        depth: 5\n",
      "        reps: 2\n",
      "        allow_bias: false\n",
      "        activation:\n",
      "          name: lrelu\n",
      "          negative_slope: 0.33\n",
      "        norm_layer:\n",
      "          name: batch_norm\n",
      "          eps: 0.0001\n",
      "          momentum: 0.01\n",
      "      ppn:\n",
      "        classify_endpoints: true\n",
      "    uresnet_ppn_loss:\n",
      "      uresnet_loss:\n",
      "        balance_loss: false\n",
      "      ppn_loss:\n",
      "        mask_loss: CE\n",
      "        resolution: 5.0\n",
      "    graph_spice:\n",
      "      shapes:\n",
      "      - shower\n",
      "      - track\n",
      "      - michel\n",
      "      - delta\n",
      "      use_raw_features: true\n",
      "      invert: true\n",
      "      make_clusters: true\n",
      "      embedder:\n",
      "        spatial_embedding_dim: 3\n",
      "        feature_embedding_dim: 16\n",
      "        occupancy_mode: softplus\n",
      "        covariance_mode: softplus\n",
      "        uresnet:\n",
      "          num_input: 4\n",
      "          filters: 32\n",
      "          input_kernel: 5\n",
      "          depth: 5\n",
      "          reps: 2\n",
      "          spatial_size: 6144\n",
      "          allow_bias: false\n",
      "          activation:\n",
      "            name: lrelu\n",
      "            negative_slope: 0.33\n",
      "          norm_layer:\n",
      "            name: batch_norm\n",
      "            eps: 0.0001\n",
      "            momentum: 0.01\n",
      "      kernel:\n",
      "        name: bilinear\n",
      "        num_features: 32\n",
      "      constructor:\n",
      "        edge_threshold: 0.1\n",
      "        min_size: 3\n",
      "        label_edges: true\n",
      "        graph:\n",
      "          name: knn\n",
      "          k: 5\n",
      "        orphan:\n",
      "          mode: radius\n",
      "          radius: 1.9\n",
      "          iterate: true\n",
      "          assign_all: true\n",
      "    graph_spice_loss:\n",
      "      name: edge\n",
      "      loss: binary_log_dice_ce\n",
      "    grappa_shower:\n",
      "      nodes:\n",
      "        source: cluster\n",
      "        shapes:\n",
      "        - shower\n",
      "        - michel\n",
      "        - delta\n",
      "        min_size: -1\n",
      "        make_groups: true\n",
      "        grouping_method: score\n",
      "      graph:\n",
      "        name: complete\n",
      "        max_length:\n",
      "        - 500\n",
      "        - 0\n",
      "        - 500\n",
      "        - 500\n",
      "        - 0\n",
      "        - 0\n",
      "        - 0\n",
      "        - 25\n",
      "        - 0\n",
      "        - 25\n",
      "        dist_algorithm: recursive\n",
      "      node_encoder:\n",
      "        name: geo\n",
      "        use_numpy: true\n",
      "        add_value: true\n",
      "        add_shape: true\n",
      "        add_points: true\n",
      "        add_local_dirs: true\n",
      "        dir_max_dist: 5\n",
      "        add_local_dedxs: true\n",
      "        dedx_max_dist: 5\n",
      "      edge_encoder:\n",
      "        name: geo\n",
      "        use_numpy: true\n",
      "      gnn_model:\n",
      "        name: meta\n",
      "        node_feats: 33\n",
      "        edge_feats: 19\n",
      "        node_pred: 2\n",
      "        edge_pred: 2\n",
      "        edge_layer:\n",
      "          name: mlp\n",
      "          mlp:\n",
      "            depth: 3\n",
      "            width: 64\n",
      "            activation:\n",
      "              name: lrelu\n",
      "              negative_slope: 0.1\n",
      "            normalization: batch_norm\n",
      "        node_layer:\n",
      "          name: mlp\n",
      "          reduction: max\n",
      "          attention: false\n",
      "          message_mlp:\n",
      "            depth: 3\n",
      "            width: 64\n",
      "            activation:\n",
      "              name: lrelu\n",
      "              negative_slope: 0.1\n",
      "            normalization: batch_norm\n",
      "          aggr_mlp:\n",
      "            depth: 3\n",
      "            width: 64\n",
      "            activation:\n",
      "              name: lrelu\n",
      "              negative_slope: 0.1\n",
      "            normalization: batch_norm\n",
      "    grappa_shower_loss:\n",
      "      node_loss:\n",
      "        name: shower_primary\n",
      "        high_purity: true\n",
      "        use_group_pred: true\n",
      "      edge_loss:\n",
      "        name: channel\n",
      "        target: group\n",
      "        high_purity: true\n",
      "    grappa_track:\n",
      "      nodes:\n",
      "        source: cluster\n",
      "        shapes:\n",
      "        - track\n",
      "        min_size: -1\n",
      "        make_groups: true\n",
      "        grouping_method: score\n",
      "      graph:\n",
      "        name: complete\n",
      "        max_length: 100\n",
      "        dist_algorithm: recursive\n",
      "      node_encoder:\n",
      "        name: geo\n",
      "        use_numpy: true\n",
      "        add_value: true\n",
      "        add_shape: false\n",
      "        add_points: true\n",
      "        add_local_dirs: true\n",
      "        dir_max_dist: 5\n",
      "        add_local_dedxs: true\n",
      "        dedx_max_dist: 5\n",
      "      edge_encoder:\n",
      "        name: geo\n",
      "        use_numpy: true\n",
      "      gnn_model:\n",
      "        name: meta\n",
      "        node_feats: 32\n",
      "        edge_feats: 19\n",
      "        edge_pred: 2\n",
      "        edge_layer:\n",
      "          name: mlp\n",
      "          mlp:\n",
      "            depth: 3\n",
      "            width: 64\n",
      "            activation:\n",
      "              name: lrelu\n",
      "              negative_slope: 0.1\n",
      "            normalization: batch_norm\n",
      "        node_layer:\n",
      "          name: mlp\n",
      "          reduction: max\n",
      "          attention: false\n",
      "          message_mlp:\n",
      "            depth: 3\n",
      "            width: 64\n",
      "            activation:\n",
      "              name: lrelu\n",
      "              negative_slope: 0.1\n",
      "            normalization: batch_norm\n",
      "          aggr_mlp:\n",
      "            depth: 3\n",
      "            width: 64\n",
      "            activation:\n",
      "              name: lrelu\n",
      "              negative_slope: 0.1\n",
      "            normalization: batch_norm\n",
      "    grappa_track_loss:\n",
      "      edge_loss:\n",
      "        name: channel\n",
      "        target: group\n",
      "    grappa_inter:\n",
      "      nodes:\n",
      "        source: group\n",
      "        shapes:\n",
      "        - shower\n",
      "        - track\n",
      "        - michel\n",
      "        - delta\n",
      "        min_size: -1\n",
      "        make_groups: true\n",
      "      graph:\n",
      "        name: complete\n",
      "        max_length:\n",
      "        - 500\n",
      "        - 500\n",
      "        - 0\n",
      "        - 0\n",
      "        - 25\n",
      "        - 25\n",
      "        - 25\n",
      "        - 0\n",
      "        - 0\n",
      "        - 0\n",
      "        dist_algorithm: recursive\n",
      "      node_encoder:\n",
      "        name: geo\n",
      "        use_numpy: true\n",
      "        add_value: true\n",
      "        add_shape: true\n",
      "        add_points: true\n",
      "        add_local_dirs: true\n",
      "        dir_max_dist: 5\n",
      "        add_local_dedxs: true\n",
      "        dedx_max_dist: 5\n",
      "      edge_encoder:\n",
      "        name: geo\n",
      "        use_numpy: true\n",
      "      gnn_model:\n",
      "        name: meta\n",
      "        node_feats: 33\n",
      "        edge_feats: 19\n",
      "        node_pred:\n",
      "          type: 5\n",
      "          primary: 2\n",
      "          orient: 2\n",
      "        edge_pred: 2\n",
      "        edge_layer:\n",
      "          name: mlp\n",
      "          mlp:\n",
      "            depth: 3\n",
      "            width: 64\n",
      "            activation:\n",
      "              name: lrelu\n",
      "              negative_slope: 0.1\n",
      "            normalization: batch_norm\n",
      "        node_layer:\n",
      "          name: mlp\n",
      "          reduction: max\n",
      "          attention: false\n",
      "          message_mlp:\n",
      "            depth: 3\n",
      "            width: 64\n",
      "            activation:\n",
      "              name: lrelu\n",
      "              negative_slope: 0.1\n",
      "            normalization: batch_norm\n",
      "          aggr_mlp:\n",
      "            depth: 3\n",
      "            width: 64\n",
      "            activation:\n",
      "              name: lrelu\n",
      "              negative_slope: 0.1\n",
      "            normalization: batch_norm\n",
      "    grappa_inter_loss:\n",
      "      node_loss:\n",
      "        type:\n",
      "          name: class\n",
      "          target: pid\n",
      "          loss: ce\n",
      "          balance_loss: true\n",
      "        primary:\n",
      "          name: class\n",
      "          target: inter_primary\n",
      "          loss: ce\n",
      "          balance_loss: true\n",
      "        orient:\n",
      "          name: orient\n",
      "          loss: ce\n",
      "      edge_loss:\n",
      "        name: channel\n",
      "        target: interaction\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "# Load configuration file of the ML chain\n",
    "cfg_path = 'generic_full_chain.cfg'\n",
    "cfg = yaml.load(open(cfg_path, 'r'), Loader=yaml.Loader)\n",
    "\n",
    "print(yaml.dump(cfg, sort_keys=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cccbc3e-9dd1-4464-8150-d79f77424c24",
   "metadata": {},
   "source": [
    "There's a lot to unpack. The details of each module in the full chain is beyond the scope of the WS, but the stucture is as presented in previous notebooks.\n",
    "\n",
    "You can focus on the `chain` configuration within the `model` block:\n",
    "\n",
    "```yaml\n",
    "      deghosting: null\n",
    "      charge_rescaling: null\n",
    "      segmentation: uresnet\n",
    "      point_proposal: ppn\n",
    "      fragmentation: graph_spice\n",
    "      shower_aggregation: grappa\n",
    "      shower_primary: grappa\n",
    "      track_aggregation: grappa\n",
    "      particle_aggregation: null\n",
    "      inter_aggregation: grappa\n",
    "      particle_identification: grappa\n",
    "      primary_identification: grappa\n",
    "      orientation_identification: grappa\n",
    "      calibration: null\n",
    "```\n",
    "\n",
    "You can see which network is performing which reconstruction task. You can note that a few modules are omitted here:\n",
    "- This a generic dataset, hence it has no ghost points (only relevant for wire TPCs)\n",
    "- The charge rescaling process is only applied when deghosting\n",
    "- The calibration is only relevant to correct for detector effects (none in this dataset)\n",
    "\n",
    "The rest of the model configuration is architectural details as to what parameters define the UResNets and the GNNs (GrapPAs). Here are the modules:\n",
    "- `uresnet_ppn`: Semantic segmentation + Point proposal\n",
    "- `graph_spice`: Fragmentation\n",
    "- `grappa_shower/track`: Aggregation of shower/track fragments\n",
    "- `grappa_inter`: Aggregation of particles, PID, primary and orientation predictions\n",
    "\n",
    "You can also see that the path to the weights for the full chain are provided under `model.weight_path`.\n",
    "\n",
    "```yaml\n",
    "  weight_path: /sdf/data/neutrino/generic/train/mpvmpr_2020_01_v04/weights/full_chain/default/snapshot-4999.ckpt\n",
    "```\n",
    "\n",
    "If you are executing this notebook anywhere but at S3DF, you must pull the weights from the path referenced on the notebook README.md and update the configuration accordingly!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72ab73d-563c-44ba-a67c-e67af3f8940d",
   "metadata": {
    "tags": []
   },
   "source": [
    "***\n",
    "***\n",
    "## 2. Running inference on one batch of data\n",
    "\n",
    "Once our ML model is fully trained and deployed, we may set our model to test mode and make use of its predictions: track vs shower separation, particle clustering, and PID to name a few. \n",
    " \n",
    "We first illustrate how to run the ML chain on one batch of data. Again, we use the main Driver:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92fa7c26-0e1c-46a0-b945-6cab4d28e0e2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ██████████   ██████████    ███   ███       ██   ███████████\n",
      "███        █  ██       ███   █    █████     ██   ██         \n",
      "  ████████    ██       ███  ███   ██  ████  ██   ██████████ \n",
      "█        ███  ██████████     █    ██     █████   ██         \n",
      " ██████████   ██            ███   ██       ███   ███████████\n",
      "\n",
      "Release version: 0.1.0\n",
      "\n",
      "$CUDA_VISIBLE_DEVICES=0\n",
      "\n",
      "Configuration processed at: ERROR: ld.so: object '/soft/xalt/3.0.2-202408282050/lib64/libxalt_init.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/soft/xalt/3.0.2-202408282050/lib64/libxalt_init.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "Linux x3006c0s13b1n0 5.14.21-150500.55.49-default #1 SMP PREEMPT_DYNAMIC Sun Feb 11 17:48:15 UTC 2024 (36baf2f) x86_64 x86_64 x86_64 GNU/Linux\n",
      "\n",
      "base: {world_size: 1, iterations: -1, seed: 0, dtype: float32, unwrap: true, log_dir: /home/azam/spine_bilal/logs/inference_logs,\n",
      "  prefix_log: true, overwrite_log: false, log_step: 1}\n",
      "io:\n",
      "  loader:\n",
      "    batch_size: 6\n",
      "    shuffle: false\n",
      "    num_workers: 4\n",
      "    collate_fn: all\n",
      "    dataset:\n",
      "      name: larcv\n",
      "      file_keys: /mnt/eagle/clone/g2/projects/Nu_Novel/DUNE/DUNE_2x2_RHC_MLreco_MR6/train_10_11.root\n",
      "      schema:\n",
      "        data: {parser: sparse3d, sparse_event: sparse3d_pcluster}\n",
      "        seg_label: {parser: sparse3d, sparse_event: sparse3d_pcluster_semantics}\n",
      "        ppn_label: {parser: particle_points, sparse_event: sparse3d_pcluster, particle_event: particle_pcluster}\n",
      "        clust_label: {parser: cluster3d, cluster_event: cluster3d_pcluster, particle_event: particle_pcluster,\n",
      "          sparse_semantics_event: sparse3d_pcluster_semantics, add_particle_info: true,\n",
      "          clean_data: true}\n",
      "        coord_label: {parser: particle_coords, particle_event: particle_pcluster,\n",
      "          cluster_event: cluster3d_pcluster}\n",
      "        graph_label: {parser: particle_graph, particle_event: particle_pcluster}\n",
      "        particles: {parser: particle, particle_event: particle_pcluster, cluster_event: cluster3d_pcluster}\n",
      "        meta: {parser: meta3d, sparse_event: sparse3d_pcluster}\n",
      "        run_info: {parser: run_info, sparse_event: sparse3d_pcluster}\n",
      "model:\n",
      "  name: full_chain\n",
      "  weight_path: /home/azam/spine_bilal/weights/\n",
      "  to_numpy: true\n",
      "  network_input: {data: data, seg_label: seg_label, clust_label: clust_label}\n",
      "  loss_input: {seg_label: seg_label, ppn_label: ppn_label, clust_label: clust_label,\n",
      "    coord_label: coord_label}\n",
      "  modules:\n",
      "    chain: {deghosting: null, charge_rescaling: null, segmentation: uresnet, point_proposal: ppn,\n",
      "      fragmentation: graph_spice, shower_aggregation: grappa, shower_primary: grappa,\n",
      "      track_aggregation: grappa, particle_aggregation: null, inter_aggregation: grappa,\n",
      "      particle_identification: grappa, primary_identification: grappa, orientation_identification: grappa,\n",
      "      calibration: null}\n",
      "    uresnet_ppn:\n",
      "      uresnet:\n",
      "        num_input: 1\n",
      "        num_classes: 5\n",
      "        filters: 32\n",
      "        depth: 5\n",
      "        reps: 2\n",
      "        allow_bias: false\n",
      "        activation: {name: lrelu, negative_slope: 0.33}\n",
      "        norm_layer: {name: batch_norm, eps: 0.0001, momentum: 0.01}\n",
      "      ppn: {classify_endpoints: true}\n",
      "    uresnet_ppn_loss:\n",
      "      uresnet_loss: {balance_loss: false}\n",
      "      ppn_loss: {mask_loss: CE, resolution: 5.0}\n",
      "    graph_spice:\n",
      "      shapes: [shower, track, michel, delta]\n",
      "      use_raw_features: true\n",
      "      invert: true\n",
      "      make_clusters: true\n",
      "      embedder:\n",
      "        spatial_embedding_dim: 3\n",
      "        feature_embedding_dim: 16\n",
      "        occupancy_mode: softplus\n",
      "        covariance_mode: softplus\n",
      "        uresnet:\n",
      "          num_input: 4\n",
      "          filters: 32\n",
      "          input_kernel: 5\n",
      "          depth: 5\n",
      "          reps: 2\n",
      "          spatial_size: 6144\n",
      "          allow_bias: false\n",
      "          activation: {name: lrelu, negative_slope: 0.33}\n",
      "          norm_layer: {name: batch_norm, eps: 0.0001, momentum: 0.01}\n",
      "      kernel: {name: bilinear, num_features: 32}\n",
      "      constructor:\n",
      "        edge_threshold: 0.1\n",
      "        min_size: 3\n",
      "        label_edges: true\n",
      "        graph: {name: knn, k: 5}\n",
      "        orphan: {mode: radius, radius: 1.9, iterate: true, assign_all: true}\n",
      "    graph_spice_loss: {name: edge, loss: binary_log_dice_ce}\n",
      "    grappa_shower:\n",
      "      nodes:\n",
      "        source: cluster\n",
      "        shapes: [shower, michel, delta]\n",
      "        min_size: -1\n",
      "        make_groups: true\n",
      "        grouping_method: score\n",
      "      graph:\n",
      "        name: complete\n",
      "        max_length: [500, 0, 500, 500, 0, 0, 0, 25, 0, 25]\n",
      "        dist_algorithm: recursive\n",
      "      node_encoder: {name: geo, use_numpy: true, add_value: true, add_shape: true,\n",
      "        add_points: true, add_local_dirs: true, dir_max_dist: 5, add_local_dedxs: true,\n",
      "        dedx_max_dist: 5}\n",
      "      edge_encoder: {name: geo, use_numpy: true}\n",
      "      gnn_model:\n",
      "        name: meta\n",
      "        node_feats: 33\n",
      "        edge_feats: 19\n",
      "        node_pred: 2\n",
      "        edge_pred: 2\n",
      "        edge_layer:\n",
      "          name: mlp\n",
      "          mlp:\n",
      "            depth: 3\n",
      "            width: 64\n",
      "            activation: {name: lrelu, negative_slope: 0.1}\n",
      "            normalization: batch_norm\n",
      "        node_layer:\n",
      "          name: mlp\n",
      "          reduction: max\n",
      "          attention: false\n",
      "          message_mlp:\n",
      "            depth: 3\n",
      "            width: 64\n",
      "            activation: {name: lrelu, negative_slope: 0.1}\n",
      "            normalization: batch_norm\n",
      "          aggr_mlp:\n",
      "            depth: 3\n",
      "            width: 64\n",
      "            activation: {name: lrelu, negative_slope: 0.1}\n",
      "            normalization: batch_norm\n",
      "    grappa_shower_loss:\n",
      "      node_loss: {name: shower_primary, high_purity: true, use_group_pred: true}\n",
      "      edge_loss: {name: channel, target: group, high_purity: true}\n",
      "    grappa_track:\n",
      "      nodes:\n",
      "        source: cluster\n",
      "        shapes: [track]\n",
      "        min_size: -1\n",
      "        make_groups: true\n",
      "        grouping_method: score\n",
      "      graph: {name: complete, max_length: 100, dist_algorithm: recursive}\n",
      "      node_encoder: {name: geo, use_numpy: true, add_value: true, add_shape: false,\n",
      "        add_points: true, add_local_dirs: true, dir_max_dist: 5, add_local_dedxs: true,\n",
      "        dedx_max_dist: 5}\n",
      "      edge_encoder: {name: geo, use_numpy: true}\n",
      "      gnn_model:\n",
      "        name: meta\n",
      "        node_feats: 32\n",
      "        edge_feats: 19\n",
      "        edge_pred: 2\n",
      "        edge_layer:\n",
      "          name: mlp\n",
      "          mlp:\n",
      "            depth: 3\n",
      "            width: 64\n",
      "            activation: {name: lrelu, negative_slope: 0.1}\n",
      "            normalization: batch_norm\n",
      "        node_layer:\n",
      "          name: mlp\n",
      "          reduction: max\n",
      "          attention: false\n",
      "          message_mlp:\n",
      "            depth: 3\n",
      "            width: 64\n",
      "            activation: {name: lrelu, negative_slope: 0.1}\n",
      "            normalization: batch_norm\n",
      "          aggr_mlp:\n",
      "            depth: 3\n",
      "            width: 64\n",
      "            activation: {name: lrelu, negative_slope: 0.1}\n",
      "            normalization: batch_norm\n",
      "    grappa_track_loss:\n",
      "      edge_loss: {name: channel, target: group}\n",
      "    grappa_inter:\n",
      "      nodes:\n",
      "        source: group\n",
      "        shapes: [shower, track, michel, delta]\n",
      "        min_size: -1\n",
      "        make_groups: true\n",
      "      graph:\n",
      "        name: complete\n",
      "        max_length: [500, 500, 0, 0, 25, 25, 25, 0, 0, 0]\n",
      "        dist_algorithm: recursive\n",
      "      node_encoder: {name: geo, use_numpy: true, add_value: true, add_shape: true,\n",
      "        add_points: true, add_local_dirs: true, dir_max_dist: 5, add_local_dedxs: true,\n",
      "        dedx_max_dist: 5}\n",
      "      edge_encoder: {name: geo, use_numpy: true}\n",
      "      gnn_model:\n",
      "        name: meta\n",
      "        node_feats: 33\n",
      "        edge_feats: 19\n",
      "        node_pred: {type: 5, primary: 2, orient: 2}\n",
      "        edge_pred: 2\n",
      "        edge_layer:\n",
      "          name: mlp\n",
      "          mlp:\n",
      "            depth: 3\n",
      "            width: 64\n",
      "            activation: {name: lrelu, negative_slope: 0.1}\n",
      "            normalization: batch_norm\n",
      "        node_layer:\n",
      "          name: mlp\n",
      "          reduction: max\n",
      "          attention: false\n",
      "          message_mlp:\n",
      "            depth: 3\n",
      "            width: 64\n",
      "            activation: {name: lrelu, negative_slope: 0.1}\n",
      "            normalization: batch_norm\n",
      "          aggr_mlp:\n",
      "            depth: 3\n",
      "            width: 64\n",
      "            activation: {name: lrelu, negative_slope: 0.1}\n",
      "            normalization: batch_norm\n",
      "    grappa_inter_loss:\n",
      "      node_loss:\n",
      "        type: {name: class, target: pid, loss: ce, balance_loss: true}\n",
      "        primary: {name: class, target: inter_primary, loss: ce, balance_loss: true}\n",
      "        orient: {name: orient, loss: ce}\n",
      "      edge_loss: {name: channel, target: interaction}\n",
      "\n",
      "Will load 1 file(s):\n",
      "  - /mnt/eagle/clone/g2/projects/Nu_Novel/DUNE/DUNE_2x2_RHC_MLreco_MR6/train_10_11.root\n",
      "\n",
      "Loading tree sparse3d_pcluster\n",
      "Loading tree sparse3d_pcluster_semantics\n",
      "Loading tree particle_pcluster\n",
      "Loading tree cluster3d_pcluster\n",
      "\n",
      "Total number of entries in the file(s): 49028\n",
      "\n",
      "Total number of entries selected: 49028\n",
      "\n",
      "Full chain configuration:\n",
      "  deghosting                 : null\n",
      "  charge_rescaling           : null\n",
      "  segmentation               : uresnet\n",
      "  point_proposal             : ppn\n",
      "  fragmentation              : graph_spice\n",
      "  shower_aggregation         : grappa\n",
      "  shower_primary             : grappa\n",
      "  track_aggregation          : grappa\n",
      "  particle_aggregation       : null\n",
      "  inter_aggregation          : grappa\n",
      "  particle_identification    : grappa\n",
      "  primary_identification     : grappa\n",
      "  orientation_identification : grappa\n",
      "  calibration                : null\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from spine.driver import Driver\n",
    "\n",
    "driver = Driver(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200d8b34-49cd-42fa-b4d1-7b51a4560c6a",
   "metadata": {},
   "source": [
    "The following line runs one forward operation of the ML chain. It has one output:\n",
    "* `data`: Python dictionary containing inputs and outputs of the network\n",
    "  * 3d spacepoints, and deposition values)\n",
    "  * truth information used for labels\n",
    "  * Meta data information such as the image index number and px to cm conversion factor\n",
    "  * Various outputs of the reco chain (clusters, semantics, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "254cd12f-e040-4791-a1f5-b7c4e0bf29d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = driver.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4b4636f-3f32-4fed-9e0a-0bc19d81262c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Data Dictionary = 141\n"
     ]
    }
   ],
   "source": [
    "print('Length of Data Dictionary =', len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9071320-d719-440f-8b49-6d82dd3c11a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['index', 'file_index', 'file_entry_index', 'data', 'seg_label', 'ppn_label', 'clust_label', 'coord_label', 'graph_label', 'particles', 'meta', 'run_info', 'segmentation', 'final_tensor', 'encoder_tensors', 'decoder_tensors', 'ppn_points', 'ppn_masks', 'ppn_layers', 'ppn_coords', 'ppn_output_coords', 'ppn_classify_endpoints', 'seg_pred', 'clust_label_adapt', 'graph_spice_coordinates', 'graph_spice_features', 'graph_spice_spatial_embeddings', 'graph_spice_feature_embeddings', 'graph_spice_covariance', 'graph_spice_occupancy', 'graph_spice_hypergraph_features', 'graph_spice_filter_index', 'graph_spice_clusts', 'graph_spice_clust_shapes', 'graph_spice_node_clusts', 'graph_spice_edge_clusts', 'graph_spice_edge_index', 'graph_spice_edge_shape', 'graph_spice_edge_attr', 'graph_spice_edge_label', 'graph_spice_edge_prob', 'graph_spice_node_coords', 'graph_spice_node_features', 'graph_spice_node_shapes', 'graph_spice_edge_pred', 'graph_spice_node_pred', 'fragment_clusts', 'fragment_shapes', 'shower_fragment_clusts', 'shower_fragment_edge_index', 'shower_fragment_start_points', 'shower_fragment_end_points', 'shower_fragment_node_pred', 'shower_fragment_edge_pred', 'shower_fragment_group_pred', 'track_fragment_clusts', 'track_fragment_edge_index', 'track_fragment_start_points', 'track_fragment_end_points', 'track_fragment_edge_pred', 'track_fragment_group_pred', 'fragment_start_points', 'fragment_end_points', 'fragment_node_pred', 'fragment_group_pred', 'particle_clusts', 'particle_shapes', 'particle_primaries', 'particle_edge_index', 'particle_start_points', 'particle_end_points', 'particle_node_type_pred', 'particle_node_primary_pred', 'particle_node_orient_pred', 'particle_edge_pred', 'particle_group_pred', 'interaction_clusts', 'accuracy', 'loss', 'num_losses', 'uresnet_loss', 'uresnet_accuracy', 'uresnet_accuracy_class_0', 'uresnet_accuracy_class_1', 'uresnet_accuracy_class_2', 'uresnet_accuracy_class_3', 'uresnet_accuracy_class_4', 'ppn_loss', 'ppn_accuracy', 'ppn_mask_loss', 'ppn_mask_accuracy', 'ppn_type_loss', 'ppn_type_accuracy', 'ppn_reg_loss', 'ppn_classify_endpoints_loss', 'ppn_classify_endpoints_accuracy', 'ppn_mask_loss_layer_0', 'ppn_mask_accuracy_layer_0', 'ppn_mask_loss_layer_1', 'ppn_mask_accuracy_layer_1', 'ppn_mask_loss_layer_2', 'ppn_mask_accuracy_layer_2', 'ppn_mask_loss_layer_3', 'ppn_mask_accuracy_layer_3', 'graph_spice_loss', 'graph_spice_accuracy', 'graph_spice_iou', 'grappa_shower_node_accuracy', 'grappa_shower_node_loss', 'grappa_shower_node_count', 'grappa_shower_edge_accuracy', 'grappa_shower_edge_loss', 'grappa_shower_edge_count', 'grappa_shower_loss', 'grappa_shower_accuracy', 'grappa_track_edge_accuracy', 'grappa_track_edge_loss', 'grappa_track_edge_count', 'grappa_track_loss', 'grappa_track_accuracy', 'grappa_inter_node_type_loss', 'grappa_inter_node_type_accuracy', 'grappa_inter_node_type_count', 'grappa_inter_node_type_accuracy_class_0', 'grappa_inter_node_type_accuracy_class_1', 'grappa_inter_node_type_accuracy_class_2', 'grappa_inter_node_type_accuracy_class_3', 'grappa_inter_node_type_accuracy_class_4', 'grappa_inter_node_primary_loss', 'grappa_inter_node_primary_accuracy', 'grappa_inter_node_primary_count', 'grappa_inter_node_primary_accuracy_class_0', 'grappa_inter_node_primary_accuracy_class_1', 'grappa_inter_node_orient_accuracy', 'grappa_inter_node_orient_loss', 'grappa_inter_node_orient_count', 'grappa_inter_edge_accuracy', 'grappa_inter_edge_loss', 'grappa_inter_edge_count', 'grappa_inter_loss', 'grappa_inter_accuracy'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf46b99-c5f4-44eb-86be-a10ca20c2a05",
   "metadata": {},
   "source": [
    "As you can see, the output of the full reconstruction chain is exhaustive, but arcane. This output is useful\n",
    "to debug each step of the reconstruction chain, but, as an analyzer, how do I interpret this information to\n",
    "build an analysis?\n",
    "\n",
    "Where are the particles? Where are the interactions?\n",
    "\n",
    "<figure>\n",
    "<img src=\"https://media.tenor.com/onfpmM94llEAAAAe/the-dark-knight-christopher-nolan.png\" style=\"width:500px\">\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f47a552-5397-4671-8afc-fca502a60437",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "## 3. Representation building\n",
    "\n",
    "Thankfully, this is where the (fragment), particle and interaction builders under\n",
    "[`spine.build`](https://github.com/DeepLearnPhysics/spine/tree/develop/spine/build)\n",
    "come in handy! Their purpose is to take the raw output of the full chain and convert\n",
    "it into human-reable representations. To construct these objects, all you need to do is\n",
    "to add the following block to the configuration:\n",
    "\n",
    "```yaml\n",
    "build:\n",
    "  mode: both\n",
    "  units: cm\n",
    "  fragments: false\n",
    "  particles: true\n",
    "  interactions: true\n",
    "```\n",
    "\n",
    "This is very simple:\n",
    "- `mode`: specifies whether the builders are to build reconstructed objects, truth reference objects, or both.\n",
    "  If you are running the reconstruction chain on data, you must set `mode` to `reco`.\n",
    "- `units`: units in which every coordinate must be expressed. Either `px` (native coordinate system of the input\n",
    "  or `cm`, detector coordinates, obtained from the meta information)\n",
    "- `fragments`: whether to build fragments or not (not useful for analysis, useful for debugging)\n",
    "- `particles`: whether to build particles or not\n",
    "- `ineractions`: whether to build interactions or not\n",
    "\n",
    "Now we can simply add this block to our initial configuration, run it and see what comes out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10da0805-7c0e-410d-bb1c-6c4286114714",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ██████████   ██████████    ███   ███       ██   ███████████\n",
      "███        █  ██       ███   █    █████     ██   ██         \n",
      "  ████████    ██       ███  ███   ██  ████  ██   ██████████ \n",
      "█        ███  ██████████     █    ██     █████   ██         \n",
      " ██████████   ██            ███   ██       ███   ███████████\n",
      "\n",
      "Release version: 0.1.0\n",
      "\n",
      "$CUDA_VISIBLE_DEVICES=0\n",
      "\n",
      "Configuration processed at: ERROR: ld.so: object '/soft/xalt/3.0.2-202408282050/lib64/libxalt_init.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/soft/xalt/3.0.2-202408282050/lib64/libxalt_init.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "Linux x3006c0s13b1n0 5.14.21-150500.55.49-default #1 SMP PREEMPT_DYNAMIC Sun Feb 11 17:48:15 UTC 2024 (36baf2f) x86_64 x86_64 x86_64 GNU/Linux\n",
      "\n",
      "base: {world_size: 1, iterations: -1, seed: 0, dtype: float32, unwrap: true, log_dir: /home/azam/spine_bilal/logs/inference_logs,\n",
      "  prefix_log: true, overwrite_log: false, log_step: 1}\n",
      "io:\n",
      "  loader:\n",
      "    batch_size: 6\n",
      "    shuffle: false\n",
      "    num_workers: 4\n",
      "    collate_fn: all\n",
      "    dataset:\n",
      "      name: larcv\n",
      "      file_keys: /mnt/eagle/clone/g2/projects/Nu_Novel/DUNE/DUNE_2x2_RHC_MLreco_MR6/train_10_11.root\n",
      "      schema:\n",
      "        data: {parser: sparse3d, sparse_event: sparse3d_pcluster}\n",
      "        seg_label: {parser: sparse3d, sparse_event: sparse3d_pcluster_semantics}\n",
      "        ppn_label: {parser: particle_points, sparse_event: sparse3d_pcluster, particle_event: particle_pcluster}\n",
      "        clust_label: {parser: cluster3d, cluster_event: cluster3d_pcluster, particle_event: particle_pcluster,\n",
      "          sparse_semantics_event: sparse3d_pcluster_semantics, add_particle_info: true,\n",
      "          clean_data: true}\n",
      "        coord_label: {parser: particle_coords, particle_event: particle_pcluster,\n",
      "          cluster_event: cluster3d_pcluster}\n",
      "        graph_label: {parser: particle_graph, particle_event: particle_pcluster}\n",
      "        particles: {parser: particle, particle_event: particle_pcluster, cluster_event: cluster3d_pcluster}\n",
      "        meta: {parser: meta3d, sparse_event: sparse3d_pcluster}\n",
      "        run_info: {parser: run_info, sparse_event: sparse3d_pcluster}\n",
      "model:\n",
      "  name: full_chain\n",
      "  weight_path: /home/azam/spine_bilal/weights/\n",
      "  to_numpy: true\n",
      "  network_input: {data: data, seg_label: seg_label, clust_label: clust_label}\n",
      "  loss_input: {seg_label: seg_label, ppn_label: ppn_label, clust_label: clust_label,\n",
      "    coord_label: coord_label}\n",
      "  modules:\n",
      "    chain: {deghosting: null, charge_rescaling: null, segmentation: uresnet, point_proposal: ppn,\n",
      "      fragmentation: graph_spice, shower_aggregation: grappa, shower_primary: grappa,\n",
      "      track_aggregation: grappa, particle_aggregation: null, inter_aggregation: grappa,\n",
      "      particle_identification: grappa, primary_identification: grappa, orientation_identification: grappa,\n",
      "      calibration: null}\n",
      "    uresnet_ppn:\n",
      "      uresnet:\n",
      "        num_input: 1\n",
      "        num_classes: 5\n",
      "        filters: 32\n",
      "        depth: 5\n",
      "        reps: 2\n",
      "        allow_bias: false\n",
      "        activation: {name: lrelu, negative_slope: 0.33}\n",
      "        norm_layer: {name: batch_norm, eps: 0.0001, momentum: 0.01}\n",
      "      ppn: {classify_endpoints: true}\n",
      "    uresnet_ppn_loss:\n",
      "      uresnet_loss: {balance_loss: false}\n",
      "      ppn_loss: {mask_loss: CE, resolution: 5.0}\n",
      "    graph_spice:\n",
      "      shapes: [shower, track, michel, delta]\n",
      "      use_raw_features: true\n",
      "      invert: true\n",
      "      make_clusters: true\n",
      "      embedder:\n",
      "        spatial_embedding_dim: 3\n",
      "        feature_embedding_dim: 16\n",
      "        occupancy_mode: softplus\n",
      "        covariance_mode: softplus\n",
      "        uresnet:\n",
      "          num_input: 4\n",
      "          filters: 32\n",
      "          input_kernel: 5\n",
      "          depth: 5\n",
      "          reps: 2\n",
      "          spatial_size: 6144\n",
      "          allow_bias: false\n",
      "          activation: {name: lrelu, negative_slope: 0.33}\n",
      "          norm_layer: {name: batch_norm, eps: 0.0001, momentum: 0.01}\n",
      "      kernel: {name: bilinear, num_features: 32}\n",
      "      constructor:\n",
      "        edge_threshold: 0.1\n",
      "        min_size: 3\n",
      "        label_edges: true\n",
      "        graph: {name: knn, k: 5}\n",
      "        orphan: {mode: radius, radius: 1.9, iterate: true, assign_all: true}\n",
      "    graph_spice_loss: {name: edge, loss: binary_log_dice_ce}\n",
      "    grappa_shower:\n",
      "      nodes:\n",
      "        source: cluster\n",
      "        shapes: [shower, michel, delta]\n",
      "        min_size: -1\n",
      "        make_groups: true\n",
      "        grouping_method: score\n",
      "      graph:\n",
      "        name: complete\n",
      "        max_length: [500, 0, 500, 500, 0, 0, 0, 25, 0, 25]\n",
      "        dist_algorithm: recursive\n",
      "      node_encoder: {name: geo, use_numpy: true, add_value: true, add_shape: true,\n",
      "        add_points: true, add_local_dirs: true, dir_max_dist: 5, add_local_dedxs: true,\n",
      "        dedx_max_dist: 5}\n",
      "      edge_encoder: {name: geo, use_numpy: true}\n",
      "      gnn_model:\n",
      "        name: meta\n",
      "        node_feats: 33\n",
      "        edge_feats: 19\n",
      "        node_pred: 2\n",
      "        edge_pred: 2\n",
      "        edge_layer:\n",
      "          name: mlp\n",
      "          mlp:\n",
      "            depth: 3\n",
      "            width: 64\n",
      "            activation: {name: lrelu, negative_slope: 0.1}\n",
      "            normalization: batch_norm\n",
      "        node_layer:\n",
      "          name: mlp\n",
      "          reduction: max\n",
      "          attention: false\n",
      "          message_mlp:\n",
      "            depth: 3\n",
      "            width: 64\n",
      "            activation: {name: lrelu, negative_slope: 0.1}\n",
      "            normalization: batch_norm\n",
      "          aggr_mlp:\n",
      "            depth: 3\n",
      "            width: 64\n",
      "            activation: {name: lrelu, negative_slope: 0.1}\n",
      "            normalization: batch_norm\n",
      "    grappa_shower_loss:\n",
      "      node_loss: {name: shower_primary, high_purity: true, use_group_pred: true}\n",
      "      edge_loss: {name: channel, target: group, high_purity: true}\n",
      "    grappa_track:\n",
      "      nodes:\n",
      "        source: cluster\n",
      "        shapes: [track]\n",
      "        min_size: -1\n",
      "        make_groups: true\n",
      "        grouping_method: score\n",
      "      graph: {name: complete, max_length: 100, dist_algorithm: recursive}\n",
      "      node_encoder: {name: geo, use_numpy: true, add_value: true, add_shape: false,\n",
      "        add_points: true, add_local_dirs: true, dir_max_dist: 5, add_local_dedxs: true,\n",
      "        dedx_max_dist: 5}\n",
      "      edge_encoder: {name: geo, use_numpy: true}\n",
      "      gnn_model:\n",
      "        name: meta\n",
      "        node_feats: 32\n",
      "        edge_feats: 19\n",
      "        edge_pred: 2\n",
      "        edge_layer:\n",
      "          name: mlp\n",
      "          mlp:\n",
      "            depth: 3\n",
      "            width: 64\n",
      "            activation: {name: lrelu, negative_slope: 0.1}\n",
      "            normalization: batch_norm\n",
      "        node_layer:\n",
      "          name: mlp\n",
      "          reduction: max\n",
      "          attention: false\n",
      "          message_mlp:\n",
      "            depth: 3\n",
      "            width: 64\n",
      "            activation: {name: lrelu, negative_slope: 0.1}\n",
      "            normalization: batch_norm\n",
      "          aggr_mlp:\n",
      "            depth: 3\n",
      "            width: 64\n",
      "            activation: {name: lrelu, negative_slope: 0.1}\n",
      "            normalization: batch_norm\n",
      "    grappa_track_loss:\n",
      "      edge_loss: {name: channel, target: group}\n",
      "    grappa_inter:\n",
      "      nodes:\n",
      "        source: group\n",
      "        shapes: [shower, track, michel, delta]\n",
      "        min_size: -1\n",
      "        make_groups: true\n",
      "      graph:\n",
      "        name: complete\n",
      "        max_length: [500, 500, 0, 0, 25, 25, 25, 0, 0, 0]\n",
      "        dist_algorithm: recursive\n",
      "      node_encoder: {name: geo, use_numpy: true, add_value: true, add_shape: true,\n",
      "        add_points: true, add_local_dirs: true, dir_max_dist: 5, add_local_dedxs: true,\n",
      "        dedx_max_dist: 5}\n",
      "      edge_encoder: {name: geo, use_numpy: true}\n",
      "      gnn_model:\n",
      "        name: meta\n",
      "        node_feats: 33\n",
      "        edge_feats: 19\n",
      "        node_pred: {type: 5, primary: 2, orient: 2}\n",
      "        edge_pred: 2\n",
      "        edge_layer:\n",
      "          name: mlp\n",
      "          mlp:\n",
      "            depth: 3\n",
      "            width: 64\n",
      "            activation: {name: lrelu, negative_slope: 0.1}\n",
      "            normalization: batch_norm\n",
      "        node_layer:\n",
      "          name: mlp\n",
      "          reduction: max\n",
      "          attention: false\n",
      "          message_mlp:\n",
      "            depth: 3\n",
      "            width: 64\n",
      "            activation: {name: lrelu, negative_slope: 0.1}\n",
      "            normalization: batch_norm\n",
      "          aggr_mlp:\n",
      "            depth: 3\n",
      "            width: 64\n",
      "            activation: {name: lrelu, negative_slope: 0.1}\n",
      "            normalization: batch_norm\n",
      "    grappa_inter_loss:\n",
      "      node_loss:\n",
      "        type: {name: class, target: pid, loss: ce, balance_loss: true}\n",
      "        primary: {name: class, target: inter_primary, loss: ce, balance_loss: true}\n",
      "        orient: {name: orient, loss: ce}\n",
      "      edge_loss: {name: channel, target: interaction}\n",
      "build: {mode: both, units: cm, fragments: false, particles: true, interactions: true}\n",
      "\n",
      "Will load 1 file(s):\n",
      "  - /mnt/eagle/clone/g2/projects/Nu_Novel/DUNE/DUNE_2x2_RHC_MLreco_MR6/train_10_11.root\n",
      "\n",
      "Loading tree sparse3d_pcluster\n",
      "Loading tree sparse3d_pcluster_semantics\n",
      "Loading tree particle_pcluster\n",
      "Loading tree cluster3d_pcluster\n",
      "\n",
      "Total number of entries in the file(s): 49028\n",
      "\n",
      "Total number of entries selected: 49028\n",
      "\n",
      "Full chain configuration:\n",
      "  deghosting                 : null\n",
      "  charge_rescaling           : null\n",
      "  segmentation               : uresnet\n",
      "  point_proposal             : ppn\n",
      "  fragmentation              : graph_spice\n",
      "  shower_aggregation         : grappa\n",
      "  shower_primary             : grappa\n",
      "  track_aggregation          : grappa\n",
      "  particle_aggregation       : null\n",
      "  inter_aggregation          : grappa\n",
      "  particle_identification    : grappa\n",
      "  primary_identification     : grappa\n",
      "  orientation_identification : grappa\n",
      "  calibration                : null\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load configuration file of the ML chain\n",
    "cfg_path = 'generic_full_chain.cfg'\n",
    "cfg = yaml.load(open(cfg_path, 'r'), Loader=yaml.Loader)\n",
    "cfg['build'] = {\n",
    "    'mode': 'both',\n",
    "    'units': 'cm',\n",
    "    'fragments': False,\n",
    "    'particles': True,\n",
    "    'interactions': True\n",
    "}\n",
    "\n",
    "driver = Driver(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6bd3bd6e-9719-4546-a24e-079020b7dfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = driver.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31816a98-c226-49fd-b086-82c4299b1bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Data Dictionary = 152\n"
     ]
    }
   ],
   "source": [
    "print('Length of Data Dictionary =', len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5db0ad-4da9-4d0b-a7cf-8bab2cb66a7a",
   "metadata": {},
   "source": [
    "You can see that the number of data products has increased, let's take a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "428468dd-7ba7-4b1a-9aff-dcd28fd34276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['index', 'file_index', 'file_entry_index', 'data', 'seg_label', 'ppn_label', 'clust_label', 'coord_label', 'graph_label', 'particles', 'meta', 'run_info', 'segmentation', 'final_tensor', 'encoder_tensors', 'decoder_tensors', 'ppn_points', 'ppn_masks', 'ppn_layers', 'ppn_coords', 'ppn_output_coords', 'ppn_classify_endpoints', 'seg_pred', 'clust_label_adapt', 'graph_spice_coordinates', 'graph_spice_features', 'graph_spice_spatial_embeddings', 'graph_spice_feature_embeddings', 'graph_spice_covariance', 'graph_spice_occupancy', 'graph_spice_hypergraph_features', 'graph_spice_filter_index', 'graph_spice_clusts', 'graph_spice_clust_shapes', 'graph_spice_node_clusts', 'graph_spice_edge_clusts', 'graph_spice_edge_index', 'graph_spice_edge_shape', 'graph_spice_edge_attr', 'graph_spice_edge_label', 'graph_spice_edge_prob', 'graph_spice_node_coords', 'graph_spice_node_features', 'graph_spice_node_shapes', 'graph_spice_edge_pred', 'graph_spice_node_pred', 'fragment_clusts', 'fragment_shapes', 'shower_fragment_clusts', 'shower_fragment_edge_index', 'shower_fragment_start_points', 'shower_fragment_end_points', 'shower_fragment_node_pred', 'shower_fragment_edge_pred', 'shower_fragment_group_pred', 'track_fragment_clusts', 'track_fragment_edge_index', 'track_fragment_start_points', 'track_fragment_end_points', 'track_fragment_edge_pred', 'track_fragment_group_pred', 'fragment_start_points', 'fragment_end_points', 'fragment_node_pred', 'fragment_group_pred', 'particle_clusts', 'particle_shapes', 'particle_primaries', 'particle_edge_index', 'particle_start_points', 'particle_end_points', 'particle_node_type_pred', 'particle_node_primary_pred', 'particle_node_orient_pred', 'particle_edge_pred', 'particle_group_pred', 'interaction_clusts', 'accuracy', 'loss', 'num_losses', 'uresnet_loss', 'uresnet_accuracy', 'uresnet_accuracy_class_0', 'uresnet_accuracy_class_1', 'uresnet_accuracy_class_2', 'uresnet_accuracy_class_3', 'uresnet_accuracy_class_4', 'ppn_loss', 'ppn_accuracy', 'ppn_mask_loss', 'ppn_mask_accuracy', 'ppn_type_loss', 'ppn_type_accuracy', 'ppn_reg_loss', 'ppn_classify_endpoints_loss', 'ppn_classify_endpoints_accuracy', 'ppn_mask_loss_layer_0', 'ppn_mask_accuracy_layer_0', 'ppn_mask_loss_layer_1', 'ppn_mask_accuracy_layer_1', 'ppn_mask_loss_layer_2', 'ppn_mask_accuracy_layer_2', 'ppn_mask_loss_layer_3', 'ppn_mask_accuracy_layer_3', 'graph_spice_loss', 'graph_spice_accuracy', 'graph_spice_iou', 'grappa_shower_node_accuracy', 'grappa_shower_node_loss', 'grappa_shower_node_count', 'grappa_shower_edge_accuracy', 'grappa_shower_edge_loss', 'grappa_shower_edge_count', 'grappa_shower_loss', 'grappa_shower_accuracy', 'grappa_track_edge_accuracy', 'grappa_track_edge_loss', 'grappa_track_edge_count', 'grappa_track_loss', 'grappa_track_accuracy', 'grappa_inter_node_type_loss', 'grappa_inter_node_type_accuracy', 'grappa_inter_node_type_count', 'grappa_inter_node_type_accuracy_class_0', 'grappa_inter_node_type_accuracy_class_1', 'grappa_inter_node_type_accuracy_class_2', 'grappa_inter_node_type_accuracy_class_3', 'grappa_inter_node_type_accuracy_class_4', 'grappa_inter_node_primary_loss', 'grappa_inter_node_primary_accuracy', 'grappa_inter_node_primary_count', 'grappa_inter_node_primary_accuracy_class_0', 'grappa_inter_node_primary_accuracy_class_1', 'grappa_inter_node_orient_accuracy', 'grappa_inter_node_orient_loss', 'grappa_inter_node_orient_count', 'grappa_inter_edge_accuracy', 'grappa_inter_edge_loss', 'grappa_inter_edge_count', 'grappa_inter_loss', 'grappa_inter_accuracy', 'points', 'depositions', 'label_tensor', 'points_label', 'depositions_label', 'label_adapt_tensor', 'depositions_label_adapt', 'reco_particles', 'truth_particles', 'reco_interactions', 'truth_interactions'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ff7874-1cc5-4a80-b49c-088534e15091",
   "metadata": {},
   "source": [
    "At the end of the list, you can see that particle and interaction objects have now been added, phew!\n",
    "\n",
    "***\n",
    "\n",
    "Now let's visualize what these particle and interaction objects look like!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f2e014-01b8-4d0b-9f6b-b4abd3f52ab6",
   "metadata": {},
   "source": [
    "Let's focus on the `*_particles` and `*_interactions` data products, which are locally-defined particle and interaction representations, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55e13337-6d86-4fd7-8d74-73508f5ae115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieving data structures.\n",
    "# Here we need to index the data structures because we have process a batch!\n",
    "entry = 0\n",
    "reco_particles     = data['reco_particles'][entry]\n",
    "truth_particles    = data['truth_particles'][entry]\n",
    "reco_interactions  = data['reco_interactions'][entry]\n",
    "truth_interactions = data['truth_interactions'][entry]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e6ef2a4-9aaa-4e95-9f21-3e05edef7bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of reco interactions: 183\n",
      "Total number of truth interactions: 27\n"
     ]
    }
   ],
   "source": [
    "# Initialize counters for reco and truth interactions\n",
    "total_reco_interactions = 0\n",
    "total_truth_interactions = 0\n",
    "\n",
    "# Iterate through all the entries in the batch\n",
    "for entry in range(len(data['reco_interactions'])):\n",
    "    # Get the number of reco interactions for the current entry\n",
    "    reco_interactions = len(data['reco_interactions'][entry])\n",
    "    truth_interactions = len(data['truth_interactions'][entry])\n",
    "    \n",
    "    # Accumulate the total number of interactions\n",
    "    total_reco_interactions += reco_interactions\n",
    "    total_truth_interactions += truth_interactions\n",
    "\n",
    "# Print the results\n",
    "print(\"Total number of reco interactions:\", total_reco_interactions)\n",
    "print(\"Total number of truth interactions:\", total_truth_interactions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbb2c7a-1b30-47b7-87a9-ac40fc734ce8",
   "metadata": {},
   "source": [
    "Let us start by taking a look at the reco particle objects, what are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd225ab3-ee21-49e8-93d4-fa92516799e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RecoParticle(id=0, index=array([22]), size=1, points=array([[ 10.419899 ,   1.9953003, -62.7411   ]], dtype=float32), depositions=array([0.23729864], dtype=float32), depositions_sum=0.23729864, sources=array([], shape=(0, 2), dtype=int64), module_ids=array([], dtype=int64), is_contained=False, is_matched=False, match_ids=array([], dtype=int64), match_overlaps=array([], dtype=float32), is_cathode_crosser=False, cathode_offset=-inf, is_truth=False, units='cm', fragments=array([], dtype=object), fragment_ids=array([], dtype=int32), num_fragments=0, interaction_id=0, shape=3, pid=1, pdg_code=11, is_primary=True, length=-1.0, start_point=array([ 10.419899 ,   1.9953003, -62.7411   ], dtype=float32), end_point=array([-inf, -inf, -inf], dtype=float32), start_dir=array([-inf, -inf, -inf], dtype=float32), end_dir=array([-inf, -inf, -inf], dtype=float32), mass=0.511998, ke=-1.0, calo_ke=-1.0, csda_ke=-1.0, mcs_ke=-1.0, momentum=array([-inf, -inf, -inf], dtype=float32), p=inf, is_valid=True, pid_scores=array([0.20376095, 0.2039035 , 0.19056122, 0.19936642, 0.20240785,\n",
       "       0.        ], dtype=float32), primary_scores=array([0.46694058, 0.5330594 ], dtype=float32), ppn_ids=array([], dtype=int32), ppn_points=array([], shape=(0, 3), dtype=float32))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reco_particles[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15019085-551f-44b1-b1a0-dabca62a69a7",
   "metadata": {},
   "source": [
    "Here's a few particle attributes that might be useful:\n",
    "- `points`: Positions of the space points associated with the particle\n",
    "- `depositions`: Amount of charge/energy associated with each space point\n",
    "- `interaction_id`: ID of the interaction this particle belongs to\n",
    "- `pid`: Particle ID (see below for meaning of those numbers)\n",
    "- `is_primary`: Whether the particle originates from the primary vertex or not\n",
    "- `start_point`: Position of the start point\n",
    "- `end_point`: Position of the end point (for EM showers, same as start point)\n",
    "\n",
    "You may also notice that some of the reconstructed quantities are not filled (e.g. `start_dir`, `is_contained`, etc. This is because these attributes are filled by the post-processors, which have not yet ran...\n",
    "\n",
    "For a comprehensive list of available attributes, simply use `help`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce73ed34-0b77-49ac-84b4-d0f6965831eb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#help(reco_particles[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f942eb-67db-4145-bc92-e819aed492ab",
   "metadata": {},
   "source": [
    "Exercise: do the same for the `truth_particles` and investigate what is in there!\n",
    "\n",
    "We can do the same for interactions.\n",
    "\n",
    "This time we use the `as_dict()` method, which restricts the list of attributes to short-form attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59399741-5c34-4664-a996-23e55725819e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reco_interactions[0].as_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1491f0-5773-49d7-af66-03e0a0ed4c94",
   "metadata": {},
   "source": [
    "How do we fill the missing attributes? Let's take a look..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c577b3da-2b2e-4177-9c53-772a9dfbc7f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "***\n",
    "***\n",
    "## 4. Post-processors\n",
    "\n",
    "Here a schematic representation of the data flow, after the execution of the full chain:\n",
    "\n",
    "<figure>\n",
    "<img src=\"https://github.com/francois-drielsma/lartpc_mlreco3d/raw/me/images/anatools.png\" style=\"width:800px\">\n",
    "</figure>\n",
    "\n",
    "The post-processing module under `spine.post` takes care of all non-ML reconstruction steps and is configured under the the `post` configuration block. Here is what the full post-processing suite would look on our generic dataset:\n",
    "\n",
    "```yaml\n",
    "post:\n",
    "  shape_logic:\n",
    "    enforce_pid: true\n",
    "    enforce_primary: true\n",
    "    priority: 3\n",
    "  direction:\n",
    "    obj_type: particle\n",
    "    optimize: true\n",
    "    run_mode: both\n",
    "    priority: 1\n",
    "  calo_ke:\n",
    "    scaling: 1.\n",
    "    shower_fudge: 1/0.83\n",
    "    priority: 1\n",
    "  csda_ke:\n",
    "    tracking_mode: step_next\n",
    "    segment_length: 5.0\n",
    "    priority: 1\n",
    "  mcs_ke:\n",
    "    tracking_mode: bin_pca\n",
    "    segment_length: 5.0\n",
    "    priority: 1\n",
    "  topology_threshold:\n",
    "    ke_thresholds:\n",
    "      4: 50\n",
    "      default: 25\n",
    "  vertex:\n",
    "    use_primaries: true\n",
    "    update_primaries: false\n",
    "    priority: 1\n",
    "  containment:\n",
    "    margin: 5.0\n",
    "    mode: meta\n",
    "  fiducial:\n",
    "    margin: 25.0\n",
    "    mode: meta\n",
    "  children_count:\n",
    "    mode: shape\n",
    "  match:\n",
    "    match_mode: both\n",
    "    ghost: false\n",
    "    fragment: false\n",
    "    particle: true\n",
    "    interaction: true\n",
    "```\n",
    "\n",
    "No need to understand in detail what each of these modules do. We will go over this again in detail in notebooks dedicated to performing these tasks or using the output of these post-processor. but it is intersting to check on our particle objects again now to see what is new..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808263a2-6977-4b1a-bb73-ef3aa3c5d709",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "# Load configuration file of the ML chain\n",
    "cfg_path = 'generic_full_chain_with_post.cfg'\n",
    "cfg = yaml.load(open(cfg_path, 'r'), Loader=yaml.Loader)\n",
    "\n",
    "print(yaml.dump(cfg, sort_keys=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73fbf73-b7dc-4f2d-b1ac-9229a50b2100",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "driver = Driver(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7d1d09-7a1a-400b-92ee-cb5c3262d5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = driver.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc1193a-345f-4f99-8798-60c1dd9a3c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by getting the particles in the first entry of the batch\n",
    "\n",
    "entry = 0\n",
    "reco_particles = data['reco_particles'][entry]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2d252a-9c19-44ff-ac64-72fe839ef81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reco_particles[3].as_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b4cfba-d9c2-497b-985d-9abcf38a5e64",
   "metadata": {},
   "source": [
    "Now you can see that there's a lot more filled! E.g.:\n",
    "- `is_contained`: Whether the particle is contained within the volume of interest\n",
    "- `start_dir`/`end_dir`: Direction estimates w.r.t. to start/end points\n",
    "- `*_ke`: estimates using calorimetry, CSDA or MCS\n",
    "- `momentum`: estimate using `start_dir`, `ke` and `pid`\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e702fe13-55b1-4d33-b274-da16431904a0",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "## 5. Storage\n",
    "\n",
    "Ok, almost done eating your vegetables, I swear. One more step to have a fully fledged inference confuration! The `writer`.\n",
    "\n",
    "This block, which lives under `io`, defines what and how to store the output of the reco. chain + the post-processors to an HDF5 file. This is useful because it is significantly more efficient to run the full chain on a dataset to start and then use the output for analysis later. This centralizes the production process and saves time for the analyzers.\n",
    "\n",
    "The writer is defined under `spine.io.write.hdf5` and is configured as follows:\n",
    "\n",
    "```\n",
    "  writer:\n",
    "    name: hdf5\n",
    "    file_name: dummy.h5\n",
    "    overwrite: true\n",
    "    keys:\n",
    "      - run_info\n",
    "      - meta\n",
    "      - points\n",
    "      - points_label\n",
    "      - depositions\n",
    "      - depositions_label\n",
    "      - reco_particles\n",
    "      - truth_particles\n",
    "      - reco_interactions\n",
    "      - truth_interactions\n",
    "```\n",
    "\n",
    "This is the basics of what goes in there:\n",
    "- `name`: type of writer to use (currently HDF5 only)\n",
    "- `file_name`: name of the output file\n",
    "- `overwrite`: if `True` and the file already exists, it will be deleted and a new file will be created in its place\n",
    "- `keys`: list of keys in the `data` dictionary output that need to be stored to the HDF5 file. The list above is the exhaustive list of things that need to be stored to be able to restore the full SPINE `*particles` and `*interactions` objects from file. If you want to make a compact file with only top level information (no points, no depositions), simply comment out the following keys:\n",
    "  - `points*`\n",
    "  - `depositions*`\n",
    "  \n",
    "This block completes the assembly of a full chain inference configuration! These configurations are mainained on this repo:\n",
    "\n",
    "```html\n",
    "https://github.com/DeepLearnPhysics/spine_prod/\n",
    "```\n",
    "\n",
    "If you look under the `config` directory, you'll see that one full chain exists for each data modality this week:\n",
    "- `generic` (generic detector-less images, i.e. no detector sim.)\n",
    "- `icarus`\n",
    "- `sbnd`\n",
    "- `2x2`\n",
    "\n",
    "Let's load one of them and make a file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6dc740-57f6-42dc-8ccd-715b61b204a1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "# Load configuration file of the ML chain\n",
    "# cfg_path = '/sdf/data/neutrino/software/spine_prod/config/generic/generic_full_chain_240718.cfg'\n",
    "cfg_path = '/home/azam/spine_bilal/spine_prod/config/generic/generic_full_chain_240718.cfg'\n",
    "cfg = yaml.load(open(cfg_path, 'r'), Loader=yaml.Loader)\n",
    "\n",
    "# cfg['io']['loader']['dataset']['file_keys'] = '/sdf/data/neutrino/public_html/spine_workshop/larcv/generic_small.root'\n",
    "cfg['io']['loader']['dataset']['file_keys'] = '/home/azam/train.root'\n",
    "\n",
    "\n",
    "print(yaml.dump(cfg, sort_keys=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f50ee65-02a8-40cc-9382-240c5065f3cd",
   "metadata": {},
   "source": [
    "Simply initialize the driver and call the `run` function (will run on the whole mini dataset):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8626e00-e39f-4596-b455-d857ff7c9ed0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "driver = Driver(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e84a191-3e12-4bef-affb-fad954e927ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e356a7-76e1-4ecf-9d50-3e442d2f7448",
   "metadata": {},
   "source": [
    "You can now see that a new file has spawned (`dummy.h5`)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cfbce7-a840-4b99-a892-5bd7a9ec6275",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6395fd8-1ea5-4719-bb71-862ac55f9470",
   "metadata": {},
   "source": [
    "In summary, provided with a full chain configuration and a set of weights, all you need to do to run inference is:\n",
    "\n",
    "```python\n",
    "import yaml\n",
    "from spine.driver import Driver\n",
    "\n",
    "driver = Driver(yaml.safe_load('/sdf/data/neutrino/software/spine_prod/config/generic/generic_full_chain_240718.cfg'))\n",
    "driver.run()\n",
    "```\n",
    "\n",
    "which is exactly equivalent to calling the following command:\n",
    "\n",
    "```bash\n",
    "python3 /path/to/spine/bin/run.py -c /sdf/data/neutrino/software/spine_prod/config/generic/generic_full_chain_240718.cfg\n",
    "```\n",
    "\n",
    "Typically this command would be run as part of batch job, as described in the training notebook!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639a7a4b-ff65-4123-8624-53b69fa8bbaf",
   "metadata": {},
   "source": [
    "In the next notebook, we'll discuss how to build an analysis with these files!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d5b466-aebd-49f7-904e-ad502eaebcfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
